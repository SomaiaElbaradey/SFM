{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure compatibility for numpy.int\n",
    "if not hasattr(np, 'int'):\n",
    "    np.int = int\n",
    "\n",
    "# Display settings for inline plotting\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "# --- Feature matching imports ---\n",
    "from feature_matching.image_load import load_images\n",
    "from feature_matching.feature_extraction import extract_sift_features\n",
    "from feature_matching.feature_matching import match_sift_descriptors\n",
    "from feature_matching.outlier_remover import filter_correspondences\n",
    "from feature_matching.utilies import (\n",
    "    build_adjacency_matrix,\n",
    "    count_total_matches,\n",
    "    display_connected_pairs\n",
    ")\n",
    "\n",
    "# --- Reconstruction imports ---\n",
    "from reconstructioning.initialization import select_initial_image_pair\n",
    "from reconstructioning.reconstruct import initialize_reconstruction\n",
    "from reconstructioning.selection import select_next_image_pair\n",
    "from reconstructioning.geometry import extract_matched_keypoints\n",
    "from reconstructioning.pnp import (\n",
    "    fetch_pnp_correspondences,\n",
    "    estimate_pose_pnp,\n",
    "    evaluate_pnp_reprojection\n",
    ")\n",
    "from reconstructioning.triangulation import triangulate_and_reproject\n",
    "from reconstructioning.reprojection_error import get_reprojection_errors\n",
    "from bundle_adjustement.solver import bundle_adjust\n",
    "\n",
    "# --- Visualization imports ---\n",
    "import open3d as o3d\n",
    "\n",
    "# --- Configuration ---\n",
    "# N_IMAGES = 48\n",
    "# IMGSET = 'dingoring'\n",
    "\n",
    "# N_IMAGES = 46\n",
    "# IMGSET = 'templering'\n",
    "\n",
    "# N_IMAGES = 85\n",
    "# IMGSET = 'eglise'\n",
    "\n",
    "N_IMAGES = 83\n",
    "IMGSET = \"wazgha\"\n",
    "\n",
    "DATA_DIR = Path('./datasets')\n",
    "\n",
    "BA_CHECKPOINTS = [3, 4, 5, 6] + [int(6 * (1.34**i)) for i in range(25)]\n",
    "\n",
    "# --- Load images and intrinsics ---\n",
    "images, K = load_images(IMGSET, N_IMAGES, DATA_DIR)\n",
    "\n",
    "# --- Feature extraction and matching ---\n",
    "keypoints, descriptors = extract_sift_features(images)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1)\n",
    "raw_matches = match_sift_descriptors(descriptors, matcher)\n",
    "\n",
    "print(f\"Before outlier removal: {count_total_matches(raw_matches)} matches\")\n",
    "display_connected_pairs(raw_matches)\n",
    "\n",
    "# Remove outliers, rebuild adjacency\n",
    "filter_correspondences(raw_matches, keypoints)\n",
    "print(\"After outlier removal:\")\n",
    "display_connected_pairs(raw_matches)\n",
    "adjacency_matrix, connected_pairs = build_adjacency_matrix(N_IMAGES, raw_matches)\n",
    "\n",
    "# --- Initialize reconstruction ---\n",
    "initial_pair = select_initial_image_pair(\n",
    "    adjacency_matrix, raw_matches, keypoints, K, top_percent=0.2\n",
    ")\n",
    "R0, t0, R1, t1, points3d_with_views = initialize_reconstruction(\n",
    "    keypoints, raw_matches, K, *initial_pair\n",
    ")\n",
    "\n",
    "# --> INSERT HERE: Initialize reprojection error lists\n",
    "image_numbers = []\n",
    "mean_reprojection_errors = []\n",
    "\n",
    "# Store poses\n",
    "R_mats = {initial_pair[0]: R0, initial_pair[1]: R1}\n",
    "t_vecs = {initial_pair[0]: t0, initial_pair[1]: t1}\n",
    "\n",
    "# Track which images are in/out of reconstruction\n",
    "resected_imgs = list(initial_pair)\n",
    "unresected_imgs = [i for i in range(N_IMAGES) if i not in resected_imgs]\n",
    "\n",
    "print(f\"Initial image pair: {resected_imgs}\")\n",
    "\n",
    "\n",
    "# --- Incremental reconstruction loop ---\n",
    "while unresected_imgs:    \n",
    "    # 1) Select next image to add\n",
    "    placed_idx, new_idx, prepend = select_next_image_pair(\n",
    "        N_IMAGES, initial_pair, resected_imgs, unresected_imgs\n",
    "    )\n",
    "\n",
    "    # 2) Collect PnP correspondences\n",
    "    points3d_with_views, pts3d_pnp, pts2d_pnp, tri_status = fetch_pnp_correspondences(\n",
    "        placed_idx, new_idx, points3d_with_views, raw_matches, keypoints\n",
    "    )\n",
    "\n",
    "    # 3) Skip if too few matches\n",
    "    if len(pts3d_pnp) < 12:\n",
    "        print(f\"Only {len(pts3d_pnp)} PnP correspondences; skipping {new_idx}\")\n",
    "        continue\n",
    "\n",
    "    # 4) Estimate new pose via PnP\n",
    "    R_res, t_res = R_mats[placed_idx], t_vecs[placed_idx]\n",
    "    print(f\"Adding image {new_idx} (from {placed_idx})\")\n",
    "    R_new, t_new = estimate_pose_pnp(pts3d_pnp, pts2d_pnp, K)\n",
    "    R_mats[new_idx], t_vecs[new_idx] = R_new, t_new\n",
    "\n",
    "    # 5) Update lists\n",
    "    if prepend:\n",
    "        resected_imgs.insert(0, new_idx)\n",
    "    else:\n",
    "        resected_imgs.append(new_idx)\n",
    "    unresected_imgs.remove(new_idx)\n",
    "\n",
    "    # 6) Evaluate reprojection of PnP\n",
    "    pnp_errs, _, avg_pnp_err, pnp_inliers = evaluate_pnp_reprojection(\n",
    "        pts3d_pnp, pts2d_pnp, R_new, t_new, K\n",
    "    )\n",
    "    print(f\"PnP avg error: {avg_pnp_err:.2f}px, inlier fraction: {pnp_inliers:.2%}\")\n",
    "\n",
    "    # 7) Triangulate new points\n",
    "    i1, i2 = (placed_idx, new_idx) if placed_idx < new_idx else (new_idx, placed_idx)\n",
    "    k1, k2, idxs1, idxs2 = extract_matched_keypoints(\n",
    "        i1, i2, keypoints, raw_matches, mask=tri_status\n",
    "    )\n",
    "    if tri_status.any():\n",
    "        args = (R_res, t_res, R_new, t_new, K,\n",
    "                points3d_with_views, placed_idx, new_idx,\n",
    "                k1, k2, idxs1, idxs2)\n",
    "        if placed_idx < new_idx:\n",
    "            points3d_with_views, tri_errs, err_l, err_r = triangulate_and_reproject(*args, reproject=True)\n",
    "        else:\n",
    "            # swap left/right for proper order\n",
    "            points3d_with_views, tri_errs, err_l, err_r = triangulate_and_reproject(\n",
    "                R_new, t_new, R_res, t_res, K,\n",
    "                points3d_with_views, new_idx, placed_idx,\n",
    "                k1, k2, idxs1, idxs2, reproject=True\n",
    "            )\n",
    "\n",
    "    # 8) Conditional bundle adjustment\n",
    "    if (0.8 < pnp_inliers < 0.95) or (5 < err_l < 10) or (5 < err_r < 10):\n",
    "        points3d_with_views, R_mats, t_vecs = bundle_adjust(\n",
    "            points3d_with_views, R_mats, t_vecs,\n",
    "            resected_imgs, keypoints, K, ftol=1e0\n",
    "        )\n",
    "    if len(resected_imgs) in BA_CHECKPOINTS or not unresected_imgs or pnp_inliers <= 0.8 or err_l >= 10 or err_r >= 10:\n",
    "        points3d_with_views, R_mats, t_vecs = bundle_adjust(\n",
    "            points3d_with_views, R_mats, t_vecs,\n",
    "            resected_imgs, keypoints, K, ftol=1e-1\n",
    "        )\n",
    "\n",
    "    # 9) Global reprojection stats\n",
    "    total_err = 0\n",
    "    for im in resected_imgs:\n",
    "        _, _, avg_err_img, _ = get_reprojection_errors(\n",
    "            im, points3d_with_views, R_mats[im], t_vecs[im], K, keypoints\n",
    "        )\n",
    "        print(f\"Image {im} reprojection err: {avg_err_img:.2f}px\")\n",
    "        total_err += avg_err_img\n",
    "    mean_err = total_err / len(resected_imgs)\n",
    "    print(f\"Mean reprojection error: {mean_err:.2f}px\\n\")\n",
    "\n",
    "    image_numbers.append(len(resected_imgs))\n",
    "    mean_reprojection_errors.append(mean_err)\n",
    "\n",
    "# Plot reprojection errors at essential steps\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(image_numbers, mean_reprojection_errors, '-o', linewidth=2, markersize=4)\n",
    "plt.grid(True)\n",
    "plt.title('Reprojection Error Evolution During SfM Reconstruction', fontsize=14)\n",
    "plt.xlabel('Number of Images Included', fontsize=12)\n",
    "plt.ylabel('Mean Reprojection Error (px)', fontsize=12)\n",
    "plt.xticks(image_numbers) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Point cloud visualization with Open3D ---\n",
    "# Extracting points under threshold\n",
    "coords = np.vstack([pt.coords.flatten() for pt in points3d_with_views])\n",
    "mask = np.abs(coords).sum(axis=1) < 100\n",
    "filtered = coords[mask]\n",
    "if filtered.size == 0:\n",
    "    raise RuntimeError(\"No valid points for visualization.\")\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(filtered)\n",
    "\n",
    "# Estimate voxel size and create voxel grid\n",
    "bbox = pcd.get_axis_aligned_bounding_box()\n",
    "diag = np.linalg.norm(bbox.get_max_bound() - bbox.get_min_bound())\n",
    "voxel_size = diag / 50\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size)\n",
    "\n",
    "# Save and visualize\n",
    "o3d.io.write_point_cloud(\"output_point_cloud.ply\", pcd)\n",
    "print(\"Saved point cloud to output_point_cloud.ply\")\n",
    "o3d.visualization.draw_geometries([pcd, voxel_grid], window_name=\"Reconstruction\")\n",
    "\n",
    "# Standalone PLY viewer\n",
    "ply = o3d.io.read_point_cloud(\"output_point_cloud.ply\")\n",
    "if ply.is_empty():\n",
    "    print(\"PLY load failed or empty.\")\n",
    "else:\n",
    "    o3d.visualization.draw_geometries([ply], window_name=\"PLY Viewer\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Successfully loaded point cloud.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Load the generated point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"output_point_cloud.ply\")\n",
    "\n",
    "# Check if point cloud loaded correctly\n",
    "if pcd.is_empty():\n",
    "    print(\"Point cloud file is empty or failed to load.\")\n",
    "else:\n",
    "    print(\"Successfully loaded point cloud.\")\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd], window_name=\"Reconstructed Point Cloud\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
